[
  "Transformers rely on self-attention to model long-range dependencies in text.",
  "Vector embeddings allow text to be represented as numerical values.",
  "Machine learning models often struggle with high-dimensional sparse data.",
  "Cosine similarity is commonly used in semantic search applications.",
  "Large language models require careful prompt engineering to reduce hallucinations.",
  "Fine-tuning can improve performance but often requires significant compute resources.",
  "LoRA adapters enable parameter-efficient fine-tuning of large models.",
  "Retrieval-Augmented Generation combines search with text generation.",
  "Vector databases are optimized for similarity search over embeddings.",
  "FAISS provides efficient nearest neighbor search for dense vectors.",
  "Chroma is a lightweight vector database designed for local development.",
  "Weaviate supports hybrid search using vectors and structured filters.",
  "Mean pooling aggregates token embeddings into a single sentence vector.",
  "Normalization ensures vector magnitudes do not affect similarity scores.",
  "Dot product similarity is sensitive to vector magnitude.",
  "Euclidean distance becomes less informative in high-dimensional spaces.",
  "Embeddings capture semantic meaning rather than exact word matches.",
  "Semantic search retrieves documents based on meaning, not keywords.",
  "Chunk size selection impacts retrieval accuracy in RAG systems.",
  "Smaller chunks improve recall but increase retrieval cost.",
  "Larger chunks provide more context but may reduce precision.",
  "Evaluation of LLM outputs often requires human judgment.",
  "Automatic metrics can fail to capture semantic correctness.",
  "Guardrails help constrain model outputs to acceptable ranges.",
  "Hallucinations occur when models generate plausible but incorrect information.",
  "Memory mechanisms allow conversational agents to retain context.",
  "Token limits constrain how much context an LLM can process.",
  "Prompt templates improve consistency across LLM calls.",
  "Chain-of-thought prompting can improve reasoning performance.",
  "Agents can decide which tools to use based on user queries.",
  "APIs abstract model complexity behind simple interfaces.",
  "Inference cost depends on token count and model size.",
  "Training large models requires distributed compute infrastructure.",
  "Scaling laws describe how performance improves with data and parameters.",
  "Embedding dimensionality affects storage and retrieval speed.",
  "Approximate nearest neighbor search trades accuracy for speed.",
  "HNSW graphs enable fast similarity search in vector spaces.",
  "Index selection depends on latency and memory constraints.",
  "Batching requests improves throughput for embedding generation.",
  "Latency is critical for real-time applications.",
  "Offline preprocessing reduces runtime computation costs.",
  "Model choice impacts both quality and operational cost.",
  "Open-source models provide flexibility and transparency.",
  "Closed-source APIs simplify deployment but limit control.",
  "Production systems require monitoring and logging.",
  "Evaluation datasets must reflect real user queries.",
  "Semantic drift can degrade retrieval quality over time.",
  "Regular re-indexing helps maintain vector database performance."
]
